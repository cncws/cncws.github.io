<!DOCTYPE html><html lang="zh-CN,en,default"><head><meta charset="UTF-8"><meta name="viewport" content="width=device-width,initial-scale=1,maximum-scale=2"><meta name="theme-color" content="#222"><meta name="generator" content="Hexo 3.9.0"><link rel="apple-touch-icon" sizes="180x180" href="/uploads/icon/drop/128x128.png"><link rel="icon" type="image/png" sizes="32x32" href="/uploads/icon/drop/32x32.png"><link rel="icon" type="image/png" sizes="16x16" href="/uploads/icon/drop/16x16.png"><link rel="mask-icon" href="/uploads/icon/drop/drop.svg" color="#222"><meta http-equiv="Cache-Control" content="no-transform"><meta http-equiv="Cache-Control" content="no-siteapp"><meta name="google-site-verification" content="NKt2iJb3Hnl6-Sm7LB-fTT7LRyi9cg5yZrB-zd0ohtk"><link rel="stylesheet" href="/css/main.css"><link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/font-awesome/5.13.0/css/all.min.css"><link rel="stylesheet" href="//cdn.jsdelivr.net/npm/pace-js@1/themes/blue/pace-theme-minimal.css"><script src="//cdn.jsdelivr.net/npm/pace-js@1/pace.min.js"></script><script id="hexo-configurations">var NexT=window.NexT||{},CONFIG={hostname:"cwscn.github.io",root:"/",scheme:"Gemini",version:"7.8.0",exturl:!1,sidebar:{position:"left",display:"post",padding:18,offset:12,onmobile:!1,width:240},copycode:{enable:!0,show_result:!0,style:"flat"},back2top:{enable:!0,sidebar:!1,scrollpercent:!0},bookmark:{enable:!1,color:"#222",save:"manual"},fancybox:!1,mediumzoom:!0,lazyload:!1,pangu:!1,comments:{style:"tabs",active:null,storage:!0,lazyload:!1,nav:null},algolia:{hits:{per_page:10},labels:{input_placeholder:"Search for Posts",hits_empty:"We didn't find any results for the search: ${query}",hits_stats:"${hits} results found in ${time} ms"}},localsearch:{enable:!0,trigger:"auto",top_n_per_article:1,unescape:!1,preload:!1},motion:{enable:!0,async:!1,transition:{post_block:"fadeIn",post_header:"slideDownIn",post_body:"slideDownIn",coll_header:"slideLeftIn",sidebar:"fadeIn"}},path:"search.xml"}</script><meta name="description" content="交叉验证（cross-validation）是一种评估泛化性能的统计学方法，它比单次划分训练集和测试集的方法更加稳定、全面。在交叉验证中，数据被多次划分，并且需要训练多个模型。最常用的交叉验证是 \(k\) 折交叉验证（ \(k\)-fold cross-validation），其中 \(k\) 是由用户指定的数字，通常取 5 或 10。在执行 5 折交叉验证时，首先将数据划分为（大致）相等的 5"><meta name="keywords" content="blog"><meta property="og:type" content="article"><meta property="og:title" content="交叉验证"><meta property="og:url" content="https://cwscn.github.io/introduction-to-ml-with-python/cross-validation/index.html"><meta property="og:site_name" content="春夏秋冬"><meta property="og:description" content="交叉验证（cross-validation）是一种评估泛化性能的统计学方法，它比单次划分训练集和测试集的方法更加稳定、全面。在交叉验证中，数据被多次划分，并且需要训练多个模型。最常用的交叉验证是 \(k\) 折交叉验证（ \(k\)-fold cross-validation），其中 \(k\) 是由用户指定的数字，通常取 5 或 10。在执行 5 折交叉验证时，首先将数据划分为（大致）相等的 5"><meta property="og:locale" content="zh-CN"><meta property="og:image" content="https://cwscn.github.io/uploads/image/introduction-to-ml-with-python/cross-validation.png"><meta property="og:image" content="https://cwscn.github.io/uploads/image/introduction-to-ml-with-python/stratified-cross-validation.png"><meta property="og:image" content="https://cwscn.github.io/uploads/image/introduction-to-ml-with-python/shuffle-split.png"><meta property="og:image" content="https://cwscn.github.io/uploads/image/introduction-to-ml-with-python/group-kfold.png"><meta property="og:updated_time" content="2020-08-22T07:34:51.049Z"><meta name="twitter:card" content="summary"><meta name="twitter:title" content="交叉验证"><meta name="twitter:description" content="交叉验证（cross-validation）是一种评估泛化性能的统计学方法，它比单次划分训练集和测试集的方法更加稳定、全面。在交叉验证中，数据被多次划分，并且需要训练多个模型。最常用的交叉验证是 \(k\) 折交叉验证（ \(k\)-fold cross-validation），其中 \(k\) 是由用户指定的数字，通常取 5 或 10。在执行 5 折交叉验证时，首先将数据划分为（大致）相等的 5"><meta name="twitter:image" content="https://cwscn.github.io/uploads/image/introduction-to-ml-with-python/cross-validation.png"><link rel="canonical" href="https://cwscn.github.io/introduction-to-ml-with-python/cross-validation/"><script id="page-configurations">CONFIG.page={sidebar:"",isHome:!1,isPost:!0,lang:"zh-CN"}</script><link rel="stylesheet" href="//cdn.jsdelivr.net/npm/aplayer@1.10.1/dist/APlayer.min.css"><link rel="stylesheet" href="//unpkg.com/video.js/dist/video-js.min.css"><link rel="stylesheet" href="/css/videojs-bilibili.css"><style>.aplayer.aplayer-arrow .aplayer-icon-loop,.aplayer.aplayer-arrow .aplayer-icon-order{display:inline-block}</style><title>交叉验证 | 春夏秋冬</title><noscript><style>.sidebar-inner,.use-motion .brand,.use-motion .collection-header,.use-motion .comments,.use-motion .menu-item,.use-motion .pagination,.use-motion .post-block,.use-motion .post-body,.use-motion .post-header{opacity:initial}.use-motion .site-subtitle,.use-motion .site-title{opacity:initial;top:initial}.use-motion .logo-line-before i{left:initial}.use-motion .logo-line-after i{right:initial}</style></noscript></head><body itemscope itemtype="http://schema.org/WebPage"><div class="container use-motion"><div class="headband"></div><header class="header" itemscope itemtype="http://schema.org/WPHeader"><div class="header-inner"><div class="site-brand-container"><div class="site-nav-toggle"><div class="toggle" aria-label="切换导航栏"><span class="toggle-line toggle-line-first"></span><span class="toggle-line toggle-line-middle"></span><span class="toggle-line toggle-line-last"></span></div></div><div class="site-meta"><a href="/" class="brand" rel="start"><span class="logo-line-before"><i></i></span><h1 class="site-title">春夏秋冬</h1><span class="logo-line-after"><i></i></span></a><p class="site-subtitle" itemprop="description">人有悲欢离合 月有阴晴圆缺</p></div><div class="site-nav-right"><div class="toggle popup-trigger"><i class="fa fa-search fa-fw fa-lg"></i></div></div></div><nav class="site-nav"><ul id="menu" class="main-menu menu"><li class="menu-item menu-item-home"><a href="/" rel="section"><i class="fa fa-home fa-fw"></i> 首页</a></li><li class="menu-item menu-item-archives"><a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i> 归档<span class="badge">295</span></a></li><li class="menu-item menu-item-categories"><a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i> 分类<span class="badge">28</span></a></li><li class="menu-item menu-item-tags"><a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i> 标签<span class="badge">116</span></a></li><li class="menu-item menu-item-收藏"><a href="/favlist/" rel="section"><i class="fa fa-star fa-fw"></i> 收藏</a></li><li class="menu-item menu-item-search"><a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i> 搜索</a></li></ul></nav><div class="search-pop-overlay"><div class="popup search-popup"><div class="search-header"><span class="search-icon"><i class="fa fa-search"></i></span><div class="search-input-container"> <input autocomplete="off" autocapitalize="off" placeholder="搜索..." spellcheck="false" type="search" class="search-input"></div><span class="popup-btn-close"><i class="fa fa-times-circle"></i></span></div><div id="search-result"><div id="no-result"><i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i></div></div></div></div><meting-js server="netease" type="playlist" id="67155774" theme="#ff5555" loop="all" order="list" preload="none" volume="" mutex="" list-folded="NaN" fixed="true"></meting-js></div></header><div class="back-to-top"><i class="fa fa-arrow-up"></i> <span>0%</span></div><main class="main"><div class="main-inner"><div class="content-wrap"><div class="content post posts-expand"><article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN"><link itemprop="mainEntityOfPage" href="https://cwscn.github.io/introduction-to-ml-with-python/cross-validation/"><span hidden itemprop="author" itemscope itemtype="http://schema.org/Person"><meta itemprop="image" content="/uploads/avatar/nekosensei.png"><meta itemprop="name" content="菜农陈文生"><meta itemprop="description" content=""></span><span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization"><meta itemprop="name" content="春夏秋冬"></span><header class="post-header"><h1 class="post-title" itemprop="name headline"> 交叉验证</h1><div class="post-meta"><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-calendar-check"></i></span> <span class="post-meta-item-text">更新于</span> <time title="修改时间：2020-08-22 15:34:51" itemprop="dateModified" datetime="2020-08-22T15:34:51+08:00">2020-08-22</time></span><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-folder"></i></span> <span class="post-meta-item-text">分类于</span> <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/books/" itemprop="url" rel="index"><span itemprop="name">书籍</span></a></span> ， <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/books/introduction-to-ml-with-python/" itemprop="url" rel="index"><span itemprop="name">Python 机器学习基础教程</span></a></span></span><span id="/introduction-to-ml-with-python/cross-validation/" class="post-meta-item leancloud_visitors" data-flag-title="交叉验证" title="阅读次数"><span class="post-meta-item-icon"><i class="fa fa-eye"></i></span> <span class="post-meta-item-text">阅读次数：</span><span class="leancloud-visitors-count"></span></span><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-comment"></i></span> <span class="post-meta-item-text">Valine：</span><a title="valine" href="/introduction-to-ml-with-python/cross-validation/#valine-comments" itemprop="discussionUrl"><span class="post-comments-count valine-comment-count" data-xid="/introduction-to-ml-with-python/cross-validation/" itemprop="commentCount"></span></a></span></div></header><div class="post-body" itemprop="articleBody"><p>交叉验证（cross-validation）是一种评估泛化性能的统计学方法，它比单次划分训练集和测试集的方法更加稳定、全面。在交叉验证中，数据被多次划分，并且需要训练多个模型。最常用的交叉验证是 <strong><span class="math inline">\(k\)</span> 折交叉验证</strong>（ <span class="math inline">\(k\)</span>-fold cross-validation），其中 <span class="math inline">\(k\)</span> 是由用户指定的数字，通常取 5 或 10。在执行 5 折交叉验证时，首先将数据划分为（大致）相等的 5 部分，每一部分叫作<strong>折</strong>（fold）。接下来训练一系列模型。使用第 1 折作为测试集，其他折（2-5）作为训练集来训练第一个模型。之后构建另一个模型，这次使用第 2 折作为测试集，其他折作为训练集……对于将数据划分为训练集和测试集的这 5 次划分，每一次都要计算精度。最后我们得到了 5 个精度值。</p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">mglearn.plots.plot_cross_validation()</span><br></pre></td></tr></table></figure><p><img src="/uploads/image/introduction-to-ml-with-python/cross-validation.png"></p><a id="more"></a><h1 id="scikit-learn-中的交叉验证">scikit-learn 中的交叉验证</h1><p>scikit-learn 是利用 <code>model_selection</code> 模块中的 <code>cross_val_score</code> 函数来实现交叉验证的。<code>cross_val_score</code> 函数的参数是我们想要评估的模型、训练数据与真实标签。</p><blockquote><p><a href="https://devdocs.io/scikit_learn/modules/generated/sklearn.model_selection.cross_val_score#sklearn.model_selection.cross_val_score" target="_blank" rel="noopener"><code>sklearn.model_selection.cross_val_score(estimator, X, y=None, groups=None, scoring=None, cv=’warn’, n_jobs=None, verbose=0, fit_params=None, pre_dispatch=‘2*n_jobs’, error_score=’raise-deprecating’)</code></a></p><p>Evaluate a score by cross-validation</p></blockquote><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> cross_val_score</span><br><span class="line"></span><br><span class="line">iris = load_iris()</span><br><span class="line">logreg = LogisticRegression()</span><br><span class="line"></span><br><span class="line">scores = cross_val_score(logreg, iris.data, iris.target)  <span class="comment"># 默认执行 3 折交叉验证</span></span><br><span class="line">print(<span class="string">'Cross-validation scores:'</span>, scores)</span><br><span class="line"></span><br><span class="line">scores = cross_val_score(logreg, iris.data, iris.target, cv=<span class="number">5</span>)</span><br><span class="line">print(<span class="string">'Cross-validation scores:'</span>, scores)</span><br><span class="line"><span class="comment"># 总结交叉验证精度的一种常用方法是计算平均值</span></span><br><span class="line">print(<span class="string">'Average cross-validation score: &#123;:.2f&#125;'</span>.format(scores.mean()))</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">Cross-validation scores: [0.96078431 0.92156863 0.95833333]</span><br><span class="line">Cross-validation scores: [1.         0.96666667 0.93333333 0.9        1.        ]</span><br><span class="line">Average cross-validation score: 0.96</span><br></pre></td></tr></table></figure><p>模型的平均精度约为 96%。观察 5 折交叉验证得到的所有 5 个精度值，还可以发现，折与折之间的精度有较大的变化，范围从 100% 精度到 90% 精度。这可能意味着模型强烈依赖于将某个折用于训练，但也可能只是因为数据集的数据量太小。</p><h1 id="交叉验证的优缺点">交叉验证的优缺点</h1><p>使用交叉验证而不是将数据单次划分为训练集和测试集，这种做法具有下列优点。首先，<code>train_test_split</code> 对数据进行随机划分。想象一下，在随机划分数据时我们很“幸运”，所有难以分类的样例都在训练集中。在这种情况下，测试集将仅包含“容易分类的”样例，并且测试集精度会高得不切实际。相反，如果我们“不够幸运”，则可能随机地将所有难以分类的样例都放在测试集中，因此得到一个不切实际的低分数。但如果使用交叉验证，每个样例都会刚好在测试集中出现一次：每个样例位于一个折中，而每个折都在测试集中出现一次。因此，模型需要对数据集中所有样本的泛化能力都很好，才能让所有的交叉验证得分（及其平均值）都很高。</p><p>对数据进行多次划分，还可以提供我们的模型对训练集选择的敏感性信息。对于 iris 数据集，我们观察到精度在 90% 到 100% 之间。这是一个不小的范围，它告诉我们将模型应用于新数据时在最坏情况和最好情况下的可能表现。</p><p>与数据的单词划分相比，交叉验证的另一个优点是我们对数据的使用更加高效。在使用 <code>train_test_split</code> 时，我们通常将 75% 的数据用于训练，25% 的数据用于评估。在使用 5 折交叉验证时，在每次迭代中我们可以使用 4/5（80%）的数据来拟合模型。在使用 10 折交叉验证时，我们可以使用 9/10（90%）的数据来拟合模型。更多的数据通常可以得到更为精确的模型。</p><p>交叉验证的主要缺点是增加了计算成本。现在我们要训练 <span class="math inline">\(k\)</span> 个模型而不是单个模型，所以交叉验证的速度要比数据的单次划分大约慢 <span class="math inline">\(k\)</span> 倍。</p><h1 id="分层-k-折交叉验证和其他策略">分层 <span class="math inline">\(k\)</span> 折交叉验证和其他策略</h1><p>将数据集划分为 <span class="math inline">\(k\)</span> 折时，从数据的前 <span class="math inline">\(k\)</span> 分之一开始划分（正如上一节所述），这可能并不总是一个好主意。例如，我们来看一下 iris 数据集。</p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">print(<span class="string">'Iris labels:\n&#123;&#125;'</span>.format(iris.target))</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">Iris labels:</span><br><span class="line">[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0</span><br><span class="line"> 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1</span><br><span class="line"> 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2</span><br><span class="line"> 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2</span><br><span class="line"> 2 2]</span><br></pre></td></tr></table></figure><p>如你所见，数据的前三分之一是类别 0，中间三分之一是类别 1，最后三分之一是类别 2。想象一下在这个数据集上进行 3 折交叉验证。第 1 折将只包含类别 0，所以在数据的第一次划分中，测试集将只包含类别 0，而训练集只包含类别 1 和 2。由于在 3 次划分中训练集和测试集中的类别都不相同，因此这个数据集上的 3 折交叉验证精度为 0。这没什么帮助，因为我们在 iris 上可以的得到比 0% 好得多的精度。</p><p>由于简单的 <span class="math inline">\(k\)</span> 折策略在这里失效了，所以 scikit-learn 在分类问题中不使用这种策略，而是使用<strong>分层 <span class="math inline">\(k\)</span> 折交叉验证</strong>（stratified <span class="math inline">\(k\)</span>-fold cross-validation）。在分层交叉验证中，我们划分数据，使每个折中类别之间的比例与整个数据集中的比例相同。</p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">print(<span class="string">'Iris labels:\n&#123;&#125;'</span>.format(iris.target))</span><br></pre></td></tr></table></figure><p><img src="/uploads/image/introduction-to-ml-with-python/stratified-cross-validation.png"></p><p>举个例子，如果 90% 的样本属于类别 A 而 10% 的样本属于类别 B，那么分层交叉验证可以确保，在每个折中 90% 的样本属于类别 A 而 10% 的样本属于类别 B。</p><p>使用分层 <span class="math inline">\(k\)</span> 折交叉验证而不是 <span class="math inline">\(k\)</span> 折交叉验证来评估一个分类器，这通常是一个好主意，因为它可以对泛化性能做出更可靠的估计。在只有 10% 的样本属于类别 B 的情况下，如果使用标准 <span class="math inline">\(k\)</span> 折交叉验证，很可能某个折中只包含类别 A 的样本。利用这个折作为测试集的话，无法给出分类器整体性能的信息。</p><p>对于回归问题，scikit-learn 默认使用标准 <span class="math inline">\(k\)</span> 折交叉验证。也可以尝试让每个折表示回归目标的不同取值，但这并不是一种常用的策略，也会让大多数用户感到以外。</p><h2 id="对交叉验证的更多控制">对交叉验证的更多控制</h2><p>我们之前看到，可以利用 cv 参数来调节 <code>cross_val_score</code> 所使用的折数。但 scikit-learn 允许提供一个<strong>交叉验证分离器</strong>（cross-validation spliter）作为 cv 参数，来对数据划分过程进行更精确的控制。对于大多数使用场景而言，回归问题默认的 <span class="math inline">\(k\)</span> 折交叉验证与分类问题的分层 <span class="math inline">\(k\)</span> 折交叉验证的表现都很好，但有些情况下你可能希望使用不同的策略。比如说，我们想要在一个分类数据集上使用标准 <span class="math inline">\(k\)</span> 折交叉验证来重现别人的结果。为了实现这一点，我们首先必须从 <code>model_selection</code> 模块中导入 <code>KFold</code> 分离器类，并用我们想要使用的折数来将其实例化。</p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> KFold</span><br><span class="line"></span><br><span class="line">kfold = KFold(n_splits=<span class="number">5</span>)</span><br><span class="line"><span class="comment"># 将kfold分离器对象作为cv参数传入cross_val_score</span></span><br><span class="line">print(<span class="string">'Cross-validation scores:\n&#123;&#125;\n'</span>.format(</span><br><span class="line">    cross_val_score(logreg, iris.data, iris.target, cv=kfold)))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 我们可以验证，在iris数据集上使用标准 3 折交叉验证确实是一个非常糟糕的注意</span></span><br><span class="line">kfold = KFold(n_splits=<span class="number">3</span>)</span><br><span class="line">print(<span class="string">'Cross-validation scores:\n&#123;&#125;\n'</span>.format(</span><br><span class="line">    cross_val_score(logreg, iris.data, iris.target, cv=kfold)))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 解决这种问题的另一个方法是将数据打乱来代替分层</span></span><br><span class="line">kfold = KFold(n_splits=<span class="number">3</span>, shuffle=<span class="literal">True</span>, random_state=<span class="number">0</span>)</span><br><span class="line">print(<span class="string">'Cross-validation scores:\n&#123;&#125;'</span>.format(</span><br><span class="line">    cross_val_score(logreg, iris.data, iris.target, cv=kfold)))</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">Cross-validation scores:</span><br><span class="line">[1.         0.93333333 0.43333333 0.96666667 0.43333333]</span><br><span class="line"></span><br><span class="line">Cross-validation scores:</span><br><span class="line">[0. 0. 0.]</span><br><span class="line"></span><br><span class="line">Cross-validation scores:</span><br><span class="line">[0.9  0.96 0.96]</span><br></pre></td></tr></table></figure><h2 id="留一法交叉验证">留一法交叉验证</h2><p>另一种常用的交叉验证方法是<strong>留一法</strong>（leave-one-out）。你可以将留一法交叉验证看作是每折只包含单个样本的 <span class="math inline">\(k\)</span> 折交叉验证。对于每次划分，选择单个数据点作为测试集。这种方法可能非常耗时，特别是对于大型数据集来说，但在小型数据集上有时可以给出更好的估计结果。</p><blockquote><p><a href="https://devdocs.io/scikit_learn/modules/generated/sklearn.model_selection.leaveoneout" target="_blank" rel="noopener"><code>class sklearn.model_selection.LeaveOneOut</code></a></p><p>Leave-One-Out cross-validator</p></blockquote><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> LeaveOneOut</span><br><span class="line"></span><br><span class="line">loo = LeaveOneOut()</span><br><span class="line">scores = cross_val_score(logreg, iris.data, iris.target, cv=loo)</span><br><span class="line">print(<span class="string">'Number of cv iterations:'</span>, len(scores))</span><br><span class="line">print(<span class="string">'Mean accuracy: &#123;:.2f&#125;'</span>.format(scores.mean()))</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">Number of cv iterations: 150</span><br><span class="line">Mean accuracy: 0.95</span><br></pre></td></tr></table></figure><h2 id="打乱划分交叉验证">打乱划分交叉验证</h2><p>另一种非常灵活的交叉验证策略是<strong>打乱划分交叉验证</strong>（shuffle-split cross-validation）。在打乱划分交叉验证中，每次划分为训练集取样 <code>train_size</code> 个点，为测试集取样 <code>test_size</code> 个（不相交的）点。将这一划分方法重复 <code>n_iter</code> 次。下图显示的是对包含 10 个点的数据集进行 4 次迭代划分，每次的训练集包含 5 个点，测试集包含 2 个点（你可以将 <code>train_size</code> 和 <code>test_size</code> 设为整数来表示这两个集合的绝对大小，也可以设为浮点数来表示占整个数据集的比例）。</p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">mglearn.plots.plot_shuffle_split()</span><br></pre></td></tr></table></figure><p><img src="/uploads/image/introduction-to-ml-with-python/shuffle-split.png"></p><blockquote><p><a href="https://devdocs.io/scikit_learn/modules/generated/sklearn.model_selection.shufflesplit" target="_blank" rel="noopener"><code>class sklearn.model_selection.ShuffleSplit(n_splits=10, test_size=’default’, train_size=None, random_state=None)</code></a></p><p>Random permutation cross-validator</p></blockquote><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> ShuffleSplit</span><br><span class="line"></span><br><span class="line"><span class="comment"># 划分为 50% 的训练集和 50% 的测试集，共运行 10 次迭代</span></span><br><span class="line">shuffle_split = ShuffleSplit(test_size=<span class="number">.5</span>, train_size=<span class="number">.5</span>, n_splits=<span class="number">10</span>, random_state=<span class="number">0</span>)</span><br><span class="line">scores = cross_val_score(logreg, iris.data, iris.target, cv=shuffle_split)</span><br><span class="line">print(<span class="string">'Cross-validation scores:\n&#123;&#125;'</span>.format(scores))</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">Cross-validation scores:</span><br><span class="line">[0.84       0.93333333 0.90666667 1.         0.90666667 0.93333333</span><br><span class="line"> 0.94666667 1.         0.90666667 0.88      ]</span><br></pre></td></tr></table></figure><p>打乱划分交叉验证可以在训练集和测试集大小之外独立控制迭代次数，这有时是很有帮助的。它还允许在每次迭代中仅使用部分数据。用这种方法对数据进行二次采样可能对大型数据集上的试验很有帮助。</p><p><code>ShuufleSplit</code> 还有一种分层的形式，，其名称为 <code>StratifiedShuffleSplit</code>，它可以为分类任务提供更可靠的结果。</p><blockquote><p><a href="https://devdocs.io/scikit_learn/modules/generated/sklearn.model_selection.stratifiedshufflesplit" target="_blank" rel="noopener"><code>class sklearn.model_selection.StratifiedShuffleSplit(n_splits=10, test_size=’default’, train_size=None, random_state=None)</code></a></p><p>Stratified ShuffleSplit cross-validator</p></blockquote><h2 id="分组交叉验证">分组交叉验证</h2><p>另一种非常常见的交叉验证适用于<strong>数据中的分组高度相关</strong>时。比如你想构建一个从人脸图片中识别情感的系统，并且收集了 100 个人的照片的数据集，其中每个人都进行了多次拍摄，分别展示了不同的情感。我们的目标是构建一个分类器，能够正确识别未包含在数据集中的人的情感。</p><p>你可以使用默认的分层交叉验证来度量分类器的性能。但是这样的话，同一个人的照片可能会同时出现在训练集和测试集中。对于分类器而言，检测训练集中出现过的人脸情感比全新的人脸要容易得多。因此，为了准确评估模型对新的人脸的泛化能力，我们必须确保训练集和测试集中包含不同人的图像。</p><p>为了实现这一点，我们可以使用 <code>GroupKFold</code>，它以 <code>groups</code> 数组作为参数，可以用来说明照片中对应的是哪个人。这里的 <code>groups</code> 数组表示数据中的分组，在创建训练集和测试集的时候不应该将其分开，也不应该与类别标签弄混。</p><p>数据分组的这种例子常见于医疗应用，你可能用来来自同一名病人的多个样本，但想要将其泛化到新的病人。同样，在语音识别领域，你的数据集中可能包含同一名发言人的多条记录，但你希望能够识别新的发言人的讲话。</p><p>下面这个示例用到了一个由 <code>groups</code> 数组指定分组的模拟数据集。这个数据集包含 12 个数据点，且对于每个数据点，<code>groups</code> 指定了该点所属的分组。一共分成 4 个组，前 3 个样本属于第一组，接下来的 4 个样本属于第二组，以此类推。</p><blockquote><p><a href="https://devdocs.io/scikit_learn/modules/generated/sklearn.model_selection.groupkfold" target="_blank" rel="noopener"><code>class sklearn.model_selection.GroupKFold(n_splits=’warn’)</code></a></p><p>K-fold iterator variant with non-overlapping groups.</p></blockquote><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> GroupKFold</span><br><span class="line"></span><br><span class="line">X, y = make_blobs(n_samples=<span class="number">12</span>, random_state=<span class="number">0</span>)</span><br><span class="line"><span class="comment"># 样本不需要按分组进行排序，这么做只是为了便于说明</span></span><br><span class="line">groups = [<span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">3</span>, <span class="number">3</span>]</span><br><span class="line">scores = cross_val_score(logreg, X, y, groups, cv=GroupKFold(n_splits=<span class="number">3</span>))</span><br><span class="line">print(<span class="string">'Cross-validation scores:\n&#123;&#125;'</span>.format(scores))</span><br></pre></td></tr></table></figure><p>基于这些标签计算得到的划分如图所示。对于每次划分，每个分组都是整体出现在训练集或测试集中。</p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">mglearn.plots.plot_group_kfold()</span><br></pre></td></tr></table></figure><p><img src="/uploads/image/introduction-to-ml-with-python/group-kfold.png"></p><p>scikit-learn 中还有很多交叉验证的划分策略，适用于更多的使用场景。标准的 <code>KFold</code>、<code>StratifiedKFold</code> 和 <code>GroupKFold</code> 是目前最常用的集中。</p></div><footer class="post-footer"><div class="post-nav"><div class="post-nav-item"><a href="/leetcode/maximum-subarray/" rel="prev" title="Maximum Subarray"><i class="fa fa-chevron-left"></i> Maximum Subarray</a></div><div class="post-nav-item"> <a href="/leetcode/unique-paths/" rel="next" title="Unique Paths">Unique Paths<i class="fa fa-chevron-right"></i></a></div></div></footer></article></div><div class="comments" id="valine-comments"></div><script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script></div><div class="toggle sidebar-toggle"><span class="toggle-line toggle-line-first"></span><span class="toggle-line toggle-line-middle"></span><span class="toggle-line toggle-line-last"></span></div><aside class="sidebar"><div class="sidebar-inner"><ul class="sidebar-nav motion-element"><li class="sidebar-nav-toc"> 文章目录</li><li class="sidebar-nav-overview"> 站点概览</li></ul><div class="post-toc-wrap sidebar-panel"><div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#scikit-learn-中的交叉验证"><span class="nav-number">1.</span> <span class="nav-text">scikit-learn 中的交叉验证</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#交叉验证的优缺点"><span class="nav-number">2.</span> <span class="nav-text">交叉验证的优缺点</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#分层-k-折交叉验证和其他策略"><span class="nav-number">3.</span> <span class="nav-text">分层 \(k\) 折交叉验证和其他策略</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#对交叉验证的更多控制"><span class="nav-number">3.1.</span> <span class="nav-text">对交叉验证的更多控制</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#留一法交叉验证"><span class="nav-number">3.2.</span> <span class="nav-text">留一法交叉验证</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#打乱划分交叉验证"><span class="nav-number">3.3.</span> <span class="nav-text">打乱划分交叉验证</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#分组交叉验证"><span class="nav-number">3.4.</span> <span class="nav-text">分组交叉验证</span></a></li></ol></li></ol></div></div><div class="site-overview-wrap sidebar-panel"><div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person"> <img class="site-author-image" itemprop="image" alt="菜农陈文生" src="/uploads/avatar/nekosensei.png"><p class="site-author-name" itemprop="name">菜农陈文生</p><div class="site-description" itemprop="description"></div></div><div class="site-state-wrap motion-element"><nav class="site-state"><div class="site-state-item site-state-posts"> <a href="/archives/"><span class="site-state-item-count">295</span> <span class="site-state-item-name">日志</span></a></div><div class="site-state-item site-state-categories"> <a href="/categories/"><span class="site-state-item-count">28</span> <span class="site-state-item-name">分类</span></a></div><div class="site-state-item site-state-tags"> <a href="/tags/"><span class="site-state-item-count">116</span> <span class="site-state-item-name">标签</span></a></div></nav></div><div class="links-of-author motion-element"><span class="links-of-author-item"><a href="https://github.com/cncws" title="GitHub → https://github.com/cncws" rel="noopener" target="_blank"><i class="fab fa-github fa-fw"></i> GitHub</a></span><span class="links-of-author-item"><a href="mailto:1031616423@qq.com" title="E-Mail → mailto:1031616423@qq.com" rel="noopener" target="_blank"><i class="fa fa-envelope fa-fw"></i> E-Mail</a></span></div><div class="cc-license motion-element" itemprop="license"> <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/en" class="cc-opacity" rel="noopener" target="_blank"><img src="/images/cc-by-nc-sa.svg" alt="Creative Commons"></a></div></div></div></aside><div id="sidebar-dimmer"></div></div></main><footer class="footer"><div class="footer-inner"><div class="copyright"> &copy; <span itemprop="copyrightYear">2020</span><span class="with-love"><i class="fa fa-heart"></i></span> <span class="author" itemprop="copyrightHolder">菜农陈文生</span></div><script src="//cdn.jsdelivr.net/npm/aplayer@1.10.1/dist/APlayer.min.js"></script><script src="//cdn.jsdelivr.net/npm/meting@2.0.1/dist/Meting.min.js"></script><script src="/js/aplayer-el.js"></script><script src="//unpkg.com/video.js/dist/video.min.js"></script><script src="/js/videojs-bilibili.js"></script><script src="/js/videojs-bilibili-el.js"></script></div></footer></div><script src="/lib/anime.min.js"></script><script src="//cdn.jsdelivr.net/gh/theme-next/theme-next-pjax@0/pjax.min.js"></script><script src="//cdn.jsdelivr.net/npm/medium-zoom@1/dist/medium-zoom.min.js"></script><script src="/lib/velocity/velocity.min.js"></script><script src="/lib/velocity/velocity.ui.min.js"></script><script src="/js/utils.js"></script><script src="/js/motion.js"></script><script src="/js/schemes/pisces.js"></script><script src="/js/next-boot.js"></script><script>
var pjax = new Pjax({
  selectors: [
    'head title',
    '#page-configurations',
    '.content-wrap',
    '.post-toc-wrap',
    '.languages',
    '#pjax'
  ],
  switches: {
    '.post-toc-wrap': Pjax.switches.innerHTML
  },
  analytics: false,
  cacheBust: false,
  scrollTo : !CONFIG.bookmark.enable
});

window.addEventListener('pjax:success', () => {
  document.querySelectorAll('script[data-pjax], script#page-configurations, #pjax script').forEach(element => {
    var code = element.text || element.textContent || element.innerHTML || '';
    var parent = element.parentNode;
    parent.removeChild(element);
    var script = document.createElement('script');
    if (element.id) {
      script.id = element.id;
    }
    if (element.className) {
      script.className = element.className;
    }
    if (element.type) {
      script.type = element.type;
    }
    if (element.src) {
      script.src = element.src;
      // Force synchronous loading of peripheral JS.
      script.async = false;
    }
    if (element.dataset.pjax !== undefined) {
      script.dataset.pjax = '';
    }
    if (code !== '') {
      script.appendChild(document.createTextNode(code));
    }
    parent.appendChild(script);
  });
  NexT.boot.refresh();
  // Define Motion Sequence & Bootstrap Motion.
  if (CONFIG.motion.enable) {
    NexT.motion.integrator
      .init()
      .add(NexT.motion.middleWares.subMenu)
      .add(NexT.motion.middleWares.postList)
      .bootstrap();
  }
  NexT.utils.updateSidebarPosition();
});
</script><script src="/js/local-search.js"></script><div id="pjax"><script>
  if (typeof MathJax === 'undefined') {
    window.MathJax = {
      loader: {
        source: {
          '[tex]/amsCd': '[tex]/amscd',
          '[tex]/AMScd': '[tex]/amscd'
        }
      },
      tex: {
        inlineMath: {'[+]': [['$', '$']]},
        tags: 'ams'
      },
      options: {
        renderActions: {
          findScript: [10, doc => {
            document.querySelectorAll('script[type^="math/tex"]').forEach(node => {
              const display = !!node.type.match(/; *mode=display/);
              const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display);
              const text = document.createTextNode('');
              node.parentNode.replaceChild(text, node);
              math.start = {node: text, delim: '', n: 0};
              math.end = {node: text, delim: '', n: 0};
              doc.math.push(math);
            });
          }, '', false],
          insertedScript: [200, () => {
            document.querySelectorAll('mjx-container').forEach(node => {
              let target = node.parentNode;
              if (target.nodeName.toLowerCase() === 'li') {
                target.parentNode.classList.add('has-jax');
              }
            });
          }, '', false]
        }
      }
    };
    (function () {
      var script = document.createElement('script');
      script.src = '//cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js';
      script.defer = true;
      document.head.appendChild(script);
    })();
  } else {
    MathJax.startup.document.state(0);
    MathJax.texReset();
    MathJax.typeset();
  }
</script><script>
NexT.utils.loadComments(document.querySelector('#valine-comments'), () => {
  NexT.utils.getScript('//unpkg.com/valine/dist/Valine.min.js', () => {
    var GUEST = ['nick', 'mail', 'link'];
    var guest = 'nick,mail,link';
    guest = guest.split(',').filter(item => {
      return GUEST.includes(item);
    });
    new Valine({
      el         : '#valine-comments',
      verify     : false,
      notify     : false,
      appId      : 'Axl15EIRi5o5AatKaxXxV4Oq-gzGzoHsz',
      appKey     : 'E0qm04UjsP0qQN1l8ME3GQ25',
      placeholder: "Just go go",
      avatar     : 'identicon',
      meta       : guest,
      pageSize   : '10' || 10,
      visitor    : true,
      lang       : 'zh-cn' || 'zh-cn',
      path       : location.pathname,
      recordIP   : true,
      serverURLs : ''
    });
  }, window.Valine);
});
</script></div></body></html>